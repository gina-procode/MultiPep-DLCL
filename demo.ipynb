{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f6810b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T13:15:39.096504Z",
     "start_time": "2024-07-07T13:15:37.331703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import  random\n",
    "import sys\n",
    "import os\n",
    "def get_random_seed(seed):\n",
    "    random.seed(seed)  \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "get_random_seed(20230226)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954c6c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T13:15:47.119693Z",
     "start_time": "2024-07-07T13:15:46.540060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, 'saved_models'))\n",
    "\n",
    "from models.DLCL import DLCL\n",
    "model = DLCL()\n",
    "model_path = os.path.join(current_dir, 'saved_models', 'model.pth')\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4473ca41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T13:15:48.902398Z",
     "start_time": "2024-07-07T13:15:48.563568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_train:50\n",
      "min_length_train:4\n",
      "max_length_test:50\n",
      "min_length_test:5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "amino_acids = 'XACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "def getSequenceData(direction: str):\n",
    "    data, label = [], []\n",
    "    max_length = 0\n",
    "    min_length = 8000\n",
    "\n",
    "    with open(direction) as f:  \n",
    "        for each in f:  \n",
    "            each = each.strip()  \n",
    "            each = each.upper()  \n",
    "            if each[0] == '>':\n",
    "                label.append(np.array(list(each[1:]), dtype=int))  # Converting string labels to numeric vectors\n",
    "            else:\n",
    "                if len(each) > max_length:  \n",
    "                    max_length = len(each)\n",
    "                elif len(each) < min_length: \n",
    "                    min_length = len(each)\n",
    "                data.append(each)\n",
    "\n",
    "    return np.array(data), np.array(label), max_length, min_length\n",
    "\n",
    "def PadEncode(data, label, max_len: int = 50):\n",
    "    # 序列编码\n",
    "    data_e, label_e, seq_length, temp = [], [], [], []\n",
    "    sign, b = 0, 0\n",
    "    for i in range(len(data)):\n",
    "        length = len(data[i])\n",
    "        if len(data[i]) > max_len:  \n",
    "            continue\n",
    "        element, st = [], data[i].strip()\n",
    "        for j in st:\n",
    "            if j not in amino_acids:  \n",
    "                sign = 1\n",
    "                break\n",
    "            index = amino_acids.index(j)  \n",
    "            element.append(index)  \n",
    "            sign = 0\n",
    "\n",
    "        if length <= max_len and sign == 0:  \n",
    "            temp.append(element)\n",
    "            seq_length.append(len(temp[b])) \n",
    "            b += 1\n",
    "            element += [0] * (max_len - length)  \n",
    "            data_e.append(element)\n",
    "            label_e.append(label[i])\n",
    "        # else:\n",
    "    return torch.LongTensor(np.array(data_e)), torch.LongTensor(np.array(label_e))\n",
    "def LabelEmbeddingData(x_train, y_train):\n",
    "    label_input = np.ones((y_train.shape[0], 21))\n",
    "    return x_train,y_train,torch.LongTensor(np.array(label_input))\n",
    "\n",
    "def data_load(train_direction=None, test_direction=None, batch=None, subtest=True, CV=False):\n",
    "    dataset_train, dataset_test = [], []\n",
    "    dataset_subtest = None\n",
    "    weight = None\n",
    "    # 加载数据\n",
    "    train_seq_data, train_seq_label, max_len_train, min_len_train = getSequenceData(train_direction)\n",
    "    test_seq_data, test_seq_label, max_len_test, min_len_test = getSequenceData(test_direction)\n",
    "    print(f\"max_length_train:{max_len_train}\")\n",
    "    print(f\"min_length_train:{min_len_train}\")\n",
    "    print(f\"max_length_test:{max_len_test}\")\n",
    "    print(f\"min_length_test:{min_len_test}\")\n",
    "    x_train, y_train= PadEncode(train_seq_data, train_seq_label, max_len_train)\n",
    "    x_train,y_train,label_input=LabelEmbeddingData(x_train, y_train)\n",
    "    #print(train_length.shape)\n",
    "    x_test, y_test= PadEncode(test_seq_data, test_seq_label, max_len_test)\n",
    "    x_test, y_test, testlabel_input= LabelEmbeddingData(x_test, y_test)\n",
    "    # Create datasets\n",
    "    train_data = TensorDataset(x_train,  y_train,label_input)\n",
    "    test_data = TensorDataset(x_test, y_test,testlabel_input)\n",
    "    dataset_train.append(DataLoader(train_data, batch_size=batch, shuffle=True))\n",
    "    dataset_test.append(DataLoader(test_data, batch_size=batch, shuffle=True))\n",
    "    return dataset_train, dataset_test, dataset_subtest, weight\n",
    "\n",
    "train_datasets, test_datasets, subtests, weight = data_load(batch=256,\n",
    "                                                                train_direction='dataset/train.txt',\n",
    "                                                                test_direction='dataset/test.txt',\n",
    "                                                                subtest=False,\n",
    "                                                                CV=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862eb0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T13:15:53.863208Z",
     "start_time": "2024-07-07T13:15:49.989643Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, data, device=\"cuda\"):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()  \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad(): \n",
    "        get_random_seed(20230226)\n",
    "        for test_data, test_label,label_input in data:\n",
    "            x = test_data.to(device)\n",
    "            label_input = label_input.to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            x,_,_,_=model(x, label_input) \n",
    "            predict = torch.sigmoid(x)  \n",
    "            predictions.extend(predict.tolist())\n",
    "            labels.extend(test_label.tolist())\n",
    "\n",
    "    return np.array(predictions), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8b68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\py\\Anaconda3\\envs\\sdsd_torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_datasets)):\n",
    "    test_dataset = test_datasets[i]\n",
    "    test_labels = []\n",
    "    for x, y, z in test_dataset:\n",
    "        test_labels.extend(y.tolist())\n",
    "    test_dataset = test_datasets[i]\n",
    "model_predictions, true_labels = predict(model, test_dataset, device=DEVICE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779d316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T13:15:58.132829Z",
     "start_time": "2024-07-07T13:15:58.109073Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolutetrue is, 0.64\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def AbsoluteTrue(y_hat, y):\n",
    "    \"\"\"\n",
    "    same\n",
    "    \"\"\"\n",
    "\n",
    "    n, m = y_hat.shape\n",
    "    score_k = 0\n",
    "    for v in range(n):\n",
    "        if list(y_hat[v]) == list(y[v]):\n",
    "            score_k += 1\n",
    "    return score_k / n\n",
    "def evaluate1(score_label, y, threshold=0.6):\n",
    "    y_hat = score_label\n",
    "    for i in range(len(y_hat)):\n",
    "        for j in range(len(y_hat[i])):\n",
    "            if y_hat[i][j] < threshold:  # threshold\n",
    "                y_hat[i][j] = 0\n",
    "            else:\n",
    "                y_hat[i][j] = 1\n",
    "    absolutetrue = AbsoluteTrue(y_hat, y)\n",
    "    # 向上取整并保留三位小数\n",
    "    print(\"absolutetrue is,\", absolutetrue)\n",
    "   \n",
    "evaluate1(model_predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7c485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdsd_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
